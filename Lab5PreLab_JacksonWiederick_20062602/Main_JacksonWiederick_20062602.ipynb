{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Images\n",
    "left_Computer = cv2.imread('computers_left.png', 0)\n",
    "Right_Computer = cv2.imread('computers_right.png', 0)\n",
    "left_DaftPunk = cv2.imread('daft_punk_left.jpg', 0)\n",
    "Right_DaftPunk = cv2.imread('daft_punk_right.jpg', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Feature Matching Helped make this with https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.html?fbclid=IwAR0fpsPcTQLmYJ6RdGzmuCp41ft09C2EMNbLnsxwSBkrzptb7hofJROIgGU\n",
    "def ImageMatching(img1, img2):\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    good = []\n",
    "\n",
    "    # ratio test as per Lowe's paper\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance<0.8*n.distance:\n",
    "            good.append(m)\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "    \n",
    "    return pts1, pts2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Epipolar Lines Calculation Helped Make this with https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.html?fbclid=IwAR0fpsPcTQLmYJ6RdGzmuCp41ft09C2EMNbLnsxwSBkrzptb7hofJROIgGU\n",
    "\n",
    "def drawlines(img1, img2, lines, pts1, pts2):\n",
    "    rows, cols = img1.shape\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for row, pt1, pt2 in zip(lines, pts1, pts2):\n",
    "        colour = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x1,y1 = map(int, [0, -row[2]/row[1]])\n",
    "        x2,y2 = map(int, [cols, -((row[2]+row[0]*cols)/row[1])])\n",
    "        #x2,y2 = abs(x2),abs(y2)\n",
    "        \n",
    "        #print(f\"{x1},{y1},{x2},{y2}\")\n",
    "\n",
    "        img1 = cv2.line(img1, (x1,y1), (x2,y2), colour, 1)\n",
    "        img1 = cv2.circle(img1, tuple(pt1), 5, colour, -1)\n",
    "        img2 = cv2.circle(img2, tuple(pt2), 5, colour, -1)\n",
    "\n",
    "    return img1, img2\n",
    "\n",
    "# def drawlines(img1,img2,lines,pts1,pts2):\n",
    "#     ''' img1 - image on which we draw the epilines for the points in img2\n",
    "#         lines - corresponding epilines '''\n",
    "#     r,c = img1.shape\n",
    "#     img1 = cv.cvtColor(img1,cv.COLOR_GRAY2BGR)\n",
    "#     img2 = cv.cvtColor(img2,cv.COLOR_GRAY2BGR)\n",
    "#     for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
    "#         color = tuple(np.random.randint(0,255,3).tolist())\n",
    "#         x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "#         x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "#         img1 = cv.line(img1, (x0,y0), (x1,y1), color,1)\n",
    "#         img1 = cv.circle(img1,tuple(pt1),5,color,-1)\n",
    "#         img2 = cv.circle(img2,tuple(pt2),5,color,-1)\n",
    "#     return img1,img2\n",
    "    \n",
    "def lines_Epiporal(pts1, pts2):\n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "\n",
    "    f, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_LMEDS)\n",
    "\n",
    "    pts1 = pts1[mask.ravel()==1]\n",
    "    pts2 = pts2[mask.ravel()==1]\n",
    "\n",
    "    \n",
    "    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2, f).reshape(-1,3)\n",
    "    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1, f).reshape(-1,3)\n",
    "\n",
    "    return pts1, pts2, lines1, lines2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#Displaying the Computer Images and there Connecting Points\n",
    "\n",
    "\n",
    "\n",
    "left_pts_computer, right_pts_computer = ImageMatching(left_Computer, Right_Computer)\n",
    "left_pts_computer2, right_pts_computer2, lines_l_comp, lines_r_comp = lines_Epiporal(left_pts_computer, right_pts_computer)\n",
    "\n",
    "\n",
    "img3, img4 = drawlines(left_Computer, Right_Computer, lines_l_comp, left_pts_computer2, right_pts_computer2)\n",
    "img5, img6 = drawlines(Right_Computer, left_Computer, lines_r_comp, right_pts_computer2, left_pts_computer2)\n",
    "\n",
    "\n",
    "final_images = np.concatenate((img3, img5), axis=1)\n",
    "cv2.imshow(\"Computers\", final_images)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#Displaying the Daftpunk Images and there Connecting Points\n",
    "\n",
    "\n",
    "\n",
    "left_pts_punk, right_pts_punk = ImageMatching(left_DaftPunk, Right_DaftPunk)\n",
    "left_pts_punk2, right_pts_punk2, lines_l_comp, lines_r_comp = lines_Epiporal(left_pts_punk, right_pts_punk)\n",
    "\n",
    "\n",
    "img7, img8 = drawlines(left_DaftPunk, Right_DaftPunk, lines_l_comp, left_pts_punk2, right_pts_punk2)\n",
    "img9,img10 = drawlines(Right_DaftPunk, left_DaftPunk, lines_r_comp, right_pts_punk2, left_pts_punk2)\n",
    "\n",
    "\n",
    "final_images = np.concatenate((img7, img9), axis=1)\n",
    "cv2.imshow(\"Daft Punk\", final_images)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3\n",
    "def pointLineSelection():\n",
    "    pass\n",
    "    #nah g, this a little to much work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}